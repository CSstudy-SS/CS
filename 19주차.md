
### 공부 주제(복습 + 추가)

- 데드락
- IPC
- 페이징 & 세그멘테이션
- 파일 시스템


## 질문

### 데드락

- **왜 현대 OS는 Deadlock을 처리하지 않을까요?**

  <details>
  1. 빈번히 발생하는 이벤트가 아니기 때문에 미연에 방지하기 위해 훨씬 더 많은 오버헤드를 들이는것이 비효율적이라고 판단함.<br>
  2. 현대 시스템의 복잡성으로 인해 교착 상태를 완전히 방지하는 것은 불가능<br>
  3. 만약 시스템에서 deadlock이 발생한 경우 시스템이 비정상적으로 작동한것을 사람이 느낀후 직적 process를 죽이는 방법으로 대처<br>
  <br></details>

- **Wait Free와 Lock Free를 비교해 주세요** 

  <details>
  Wait-free와 Lock-free는 모두 멀티스레딩 환경에서 공유 자원에 대한 동시 접근을 처리하는 기술<br>
  Wait-free는 모든 스레드가 동시에 진행될 수 있는 것에 비해,<br>
  Lock-free는 일부 스레드가 블로킹될 가능성이 있지만, 구현이 더 쉽고 성능이 높은 경우가 많음. Lock-free에 wait-free가 포함됨.<br>
  참고 : https://peonyf.tistory.com/entry/OS-DeadLock%EB%8D%B0%EB%93%9C%EB%9D%BD
  </details>

- **세마포어,뮤텍스와 모니터 VS  Wait-Free, Lock-Free**

  <details>
  세마포어, 뮤텍스, 모니터와 Wait-Free, Lock-Free는 동시성 제어를 처리하는 다양한 동기화 방법입니다.<br>
  세마포어, 뮤텍스, 그리고 모니터는 Lock을 사용하는 Locking 매커니즘<br>
  Wait-Free, Lock-Free : Lock대신 CAS를 이용하여 동기화 하는 기술(atomic operation)<br>
  </details>

- **CAS란?(꼬리질문)**

  <details>
  동시성 제어에서 사용되는 원자적(atomic) 연산(실행 중에 다른 작업에 의해 방해받지 않고, 완전히 실행되거나 실행되지 않는 연산)<br>
  gpt4의 말씀<br>
  - CAS(Check-and-Swap) 연산은 주어진 주소의 값을 비교하고, 값이 일치하는 경우에만 새로운 값으로 교체하는 연산입니다. CAS 연산은 원자적(atomic) 연산으로, 동시에 여러 스레드에서 해당 연산을 수행해도 문제가 발생하지 않도록 보장됩니다.<br>
  CAS 연산을 사용하는 과정에서 다른 스레드가 메인 메모리에 저장된 값을 변경하는 경우, 현재 스레드는 CAS 연산을 수행하기 전에 먼저 메인 메모리로부터 값을 가져옵니다. 이렇게 가져온 값과 현재 스레드에 저장된 값을 비교합니다.<br>
  
  만약, 현재 스레드에 저장된 값과 메인 메모리에 저장된 값이 일치한다면, CAS 연산이 성공하고 새로운 값을 저장하게 됩니다. 하지만, 다른 스레드가 메인 메모리에 저장된 값을 변경했다면, 현재 스레드에 저장된 값과 메인 메모리에 저장된 값은 일치하지 않을 것입니다. 이 경우 CAS 연산은 실패하고, 재시도를 수행해야 합니다.<br>
  
  재시도 시에는 현재 스레드가 메인 메모리로부터 값을 다시 가져온 후, CAS 연산을 다시 시도합니다. 이렇게 함으로써, 다른 스레드에 의해 메인 메모리에 저장된 값이 변경되었을 경우에도 CAS 연산이 올바르게 동작할 수 있습니다.<br>
  
  따라서, CAS 연산은 현재 스레드에 저장된 값과 메인 메모리에 저장된 값을 반복적으로 비교하고, 일치하지 않을 경우 재시도를 수행하여 올바른 값을 찾아내는 방식으로 작동합니다.<br>
  참고 : https://steady-coding.tistory.com/568
  </details>
  

------

### IPC 

- **Sharde Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해주세요**

  <details>
  공유 메모리 방식은 IPC의 한 종류로, 여러 프로세스가 하나의 메모리 영역을 공유하여 데이터를 주고 받는 방식입니다.<br>
  유의할 점<br>
  - 동기화 : 공유 메모리에 접근하는 여러 프로세스들은 동시에 메모리에 접근할 수 있습니다. 이때, 각 프로세스가 데이터를 읽고 쓰는 시점이 일치하지 않을 수 있으므로, 데이터의 일관성을 유지하기 위해 동기화 작업이 필요합니다.<br><br>
  - 권한 : 공유 메모리에 접근하는 프로세스들은 서로 다른 권한을 가질 수 있습니다. 따라서, 공유 메모리에 접근하는 프로세스들의 권한을 관리하고 제어하는 작업이 필요합니다.<br><br>
  - 메모리 누수 : 공유 메모리를 사용할 때에는 메모리 누수에 대한 문제도 고려해야 합니다. 프로세스가 종료되더라도, 메모리에서 할당된 공간이 해제되지 않으면 메모리 누수가 발생합니다. 따라서, 공유 메모리를 사용할 때에는 메모리 할당과 해제를 꼭 확인해야 합니다.<br><br>
  - 성능 : 공유 메모리 방식은 다른 IPC 방식에 비해 빠른 속도로 데이터를 전달할 수 있습니다. 하지만, 공유 메모리에 접근하는 작업이 많을수록 성능이 저하될 수 있으므로, 적절한 크기의 메모리를 할당하고 최소한으로 접근하는 것이 좋습니다.
  </details>

- **IPC 모델에 메세지 전달방식과 공유메모리방식이 있는데 각각의 장단점**

  <details>
  공유 메모리 모델의 경우, 커널의 관여 없이 메모리를 직접 사용하여 통신하기 때문에 통신 속도가 빠른 장점이 있지만, 별도의 동기화 과정이 필요하며 동시에 메모리 위치를 접근하는 문제가 발생할 수 있다는 단점이 있다. <br>
  따라서 별도의 접근 제어 방법이 필요하며, 접근 제어 방식은 locking이나 세마포어(semaphore) 등이 있다.<br><br>
  메시지 전달 모델의 경우, 커널을 통해서 데이터를 주고 받기 때문에 통신 속도가 느리다는 단점이 있지만, <br>
  커널에서 데이터를 주고 받는 과정을 컨트롤할 수 있어 안전하며 send/receive 연산에 대해 커널이 동기화를 제공해준다는 장점이 있다.
  </details>

  

------

### 페이징 & 세그멘테이션


- **메인 메모리란?**

  <details>
  - 메인 메모리는 CPU가 직접 접근할 수 있는 기억 장치<br>
  - 프로세스가 실행되려면 프로그램이 메모리에 올라와야 함<br>
  </details>

- **프로그램을 메모리에서 실행하는 이유는?**

  <details>
  - 느리고 값싼 하드디스크는 제2저장장치로 사용<br>
  - 비싸고 빠른 메모리는 작업공간으로 사용<br>
  - 메모리를 계층적 구조로 만들어 작업속도를 올리고, 가격을 낮추는 방법을 “계층적 메모리 구조”라고 한다.<br>
  - **프로그램을 메모리에서 실행하는 이유는 CPU가 바로 접근하여 처리할 수 있기 때문**<br>
  - 디스크나 다른 저장장치에서 프로그램을 실행하면 CPU가 더 많은 시간을 소비하게 되어 작업이 더디게 처리됩니다.<br>
  </details>

- **MMU란?**

  <details>
  - MMU가 지원되지 않으면 물리 주소를 직접 접근해야 하기 때문에 부담<br>
  - MMU는 사용자가 기억장소를 일일이 할당해야하는 불편 없애준다.<br>
  - 프로세스의 크기가 실제 메모리의 용량을 초과해도 실행될 수 있게 해준다.<br>
  - 가상주소를 물리주소로 변환<br>
  </details>

- **그렇다면 가상메모리의 용량이 실제 메모리보다 클 경우에는 어떤 일이 발생할까요?**

  <details>
  당장은 paging 시스템을 이용하여 실제 메모리에 필요한 부분만을 불러오기 때문에 큰 문제가 발생하지는 않지만, 디스크에서 메모리를 불러오는 과정에서 성능 저하가 일어 날 수 있다.
  </details>

- **페이지를 교체하는 과정에 대해서 설명해주세요. (알고리즘은 아무거나)**

  <details>
  - 프로세스가 실행될 때, CPU는 페이지 테이블(Page Table)을 참조하여 가상 주소(Virtual Address)를 물리 주소(Physical Address)로 변환한다.<br>
  - 페이지 테이블은 각 페이지의 위치 정보를 가지고 있으며, 페이지 테이블 엔트리(PTE)는 해당 페이지가 메모리(RAM)에 존재하는지 여부를 표시한다.<br>
  - CPU가 페이지 테이블을 참조할 때 해당 페이지가 메모리(RAM)에 없다면, 페이지 부재(Page Fault)가 발생.<br>
  - 페이지 교체 알고리즘이 사용되어 메모리(RAM)에 필요한 페이지를 가져와 페이지 테이블의 PTE를 갱신<br>
  </details>

- **가상 주소를 실제 주소로 변환하는 과정은?**

  <details>
  - CPU에서 가상주소를 생성하고 MMU에게 전달한다.<br>
  - MMU는 가상주소에서 페이지번호를 추출 (앞 비트)<br>
  - 해당 페이지번호에 맞는 페이지 테이블을 탐색<br>
  - 페이지테이블에서 물리 페이지 프레임 번호를 가져옴.<br>
  - 가저울 물리페이지 프레임 + 가상주소의 오프셋 ⇒ 실제 주소<br>
  - 메모리에 실제주소를 이용하여 데이터를 가져옴.<br>
  </details>

- **TLB에 대해 설명해주시고 TLB를 포함하여 다시 과정을 설명해주시겠어요?**

  <details>
  Translation Lookaside Buffer<br>
  - 가상 메모리 주소를 물리적인 주소로 바로 변환하는 캐시<br>
  ⇒ 캐시 히트에 대한 설명을 추가<br>
  </details>

- **TLBmiss와 PageFault의 차이?**

  <details>
  기본 TLB miss는 TLB엔 없지만 main memory에는 올라가 있는 상태를 의미한다. 그러니 page table을 가져와서 TLB에 저장하면 간단히 해결된다. 10 cycle정도면 TLB에 정보를 저장할 수 있다. 하드웨어나 소프트웨어의 통제를 받는데 하나의 exception이라고 보면 된다. <br><br>
  하지만 Page Fault는 다르다. 요청한 page가 main memory에 없는 상태를 의미한다.
  그러니 hard disk에서부터 불러와야 한다. 그러니 약 1,000,000 cycle정도 소요해야 TLB에 정보를 저장할 수 있다. 엄청난 차이가 있는데 이러니 page Fault를 최대한 발생시키지 않아야 한다.
  </details>

- **그러면 메모리 할당 방법중 하나인 버디 시스템에 대하여 설명해주시고, 과정을 설명해주세요.**

  <details>
  - 2의 제곱 값으로 메모리를 분할한다.<br>
  - 메모리가 할당되면 적당한 크기의 메모리를 찾는다.<br>
      1. 적당한 크기의 메모리를 발견하면 할당한다.<br>
      2. 적당한 크기의 메모리 슬롯이 발견되지 않으면, 적당한 메모리 슬롯을 만들기를 시도한다.<br>
          a. 요청된 메모리 크기보다 크게 절반씩 빈 메모리 슬롯을 자른다.<br>
          b. 하한선에 도착하게 되면, 해당 메모리(하한선 크기의 메모리)를 할당한다.<br>
          c. 다시 첫 번째 단계로 돌아간다.(적당한 크기의 메모리를 찾기 위해서)<br>
          d. 적당한 메모리 슬롯이 발견될 때까지, 이 과정을 반복한다.<br>
  - 메모리가 해제되면<br>
      1. 메모리 블록을 해제한다.<br>
      2. 주변의 블록들을 살펴 본다 - 주변 블록들도 해제된 상태인가?<br>
      3. 만약 그렇다면, 두 메모리 블록을 조합하고 다시 두 번째 단계로 돌아간다. 그리고 해제된 모든 메모리들이 상한선에 도달할 때까지 이 과정을 반복하거나, 해제되지 않은 주변 블록들을 마주칠 때까지 반복한다.
  </details>

------

### 파일시스템


- **파일시스템에서 순차접근에 대해 설명해주세요.**

  <details>
  가장 간단한 접근 방법으로, 대부분 연산은 read와 write <br>
  현재 위치를 가리키는 포인터에서 시스템 콜이 발생할 경우 포인터를 앞으로 보내면서 read와 write를 진행. 뒤로 돌아갈 땐 지정한 offset만큼 되감기를 해야 한다. (테이프 모델 기반)<br>
  </details>

- **파일시스템에서 직접접근에 대하여 설명해주세요.**

  <details>
  특별한 순서없이, 빠르게 레코드를 read, write 가능<br>
  대규모 정보를 접근할 때 유용하기 때문에 '데이터베이스'에 활용된다.<br>
  </details>

- **직접접근의 장단점은?**

  <details>
  <장점>
  <br>
  파일의 임의 위치에 빠르게 액세스할 수 있으므로 파일을 읽고 쓰는 속도를 향상시킬 수 있다.<br><br>
  
  예를 들어, 비디오나 음악 파일 같은 대용량 파일에서는 파일의 일부만 읽어들이는 경우가 많기 때문에, 이러한 파일을 직접접근하는 것이 더 효율적이다.<br><br>
  
  <단점>
  <br>
  파일의 임의 위치를 액세스하다가 잘못된 위치를 읽거나 쓰면 파일의 일부 또는 전체가 손상될 수 있습니다. 또한, 파일의 일부를 읽거나 쓸 때 데이터 일관성 문제가 발생할 수 있다.
  </details>

- **그렇다면 파일시스템의 Journaling에 대해 설명해주세요.**

  <details>
  Journaling은 파일시스템에서 데이터 일관성을 유지하기 위한 방법 중 하나이다.<br>
  Journaling은 파일시스템의 동작 중 발생하는 문제를 사전에 예방하기 위해 변경 내용을 로그에 기록하는 방식이다.<br>
  </details>


  


------

### 정리 링크
